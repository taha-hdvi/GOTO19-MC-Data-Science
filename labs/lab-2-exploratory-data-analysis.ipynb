{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "**Q&A:** Why is exploratory data analysis important?\n",
    "\n",
    "\n",
    "In the last session, we learned about `NumPy`, a popularly used data science tool. In this session, we will be learning about `Pandas`, Python Data Analysis Library, an even more popularly used data science tool for data exploration and wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Pandas?\n",
    "\n",
    "<img src='https://i.ytimg.com/vi/ZjQa_YJ9qP4/maxresdefault.jpg' width='50%'>\n",
    "\n",
    "Pandas is a Python library with two primary data structures: `DataFrame` and `Series`.\n",
    "\n",
    "- A `Series` is a sequence of items, where each item has a unique label, called an `index`.\n",
    "- A `DataFrame` is a table of data. Each row has a unique row index, and each column has a unique column index. In a dataframe, each column is a `Series`.\n",
    "\n",
    "Pandas dataframe comes with a lot of useful methods that have been implemented and optimized to wrangle relatively large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download some data to play with\n",
    "# source: UCI ML Repo ()\n",
    "!mkdir ./data/car_evaluation\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names > ./data/car_evaluation/car.names\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data > ./data/car_evaluation/car.data\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.c45-names > ./data/car_evaluation/car.c45-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about the dataset\n",
    "!cat ./data/car_evaluation/car.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt     # this is a visualization tool\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reading-files\"></a>\n",
    "### Reading Files, Selecting Columns, and Summarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `car.data` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = './data/car_evaluation/car.data'\n",
    "with open(f_path, 'r') as file:\n",
    "    df = [x.strip().split(',') for x in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['buying', 'maint', 'doors', 'person', 'lug_boot', 'safety', 'class']\n",
    "df = pd.read_csv(f_path, delimiter=',', names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine the cars data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)             # DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the row and column indices of `df` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The row index (aka \"the row labels\" — in this case integers)\n",
    "df.index            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names (which is \"an index\")\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatypes of each column — each column is stored as an ndarray, which has a datatype\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How big is the dataframe?\n",
    "**Q&A**: how do we define the size of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1728 * 7 * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All values as a NumPy array\n",
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concise summary (including memory usage) — useful to quickly see if nulls exist\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select or index data.**<br>\n",
    "Pandas `DataFrame`s have structural similarities with Python-style lists and dictionaries.  \n",
    "In the example below, we select a column of data using the name of the column in a similar manner to how we select a dictionary value with the dictionary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column — returns a Pandas Series (essentially an ndarray with an index)\n",
    "df['buying'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame columns are Pandas Series.\n",
    "type(df['buying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want the dataframe output type\n",
    "df[['buying']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[['buying']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one column using the DataFrame attribute.\n",
    "type(df.buying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.buying.to_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.buying).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarize (describe) the data.**<br>\n",
    "Pandas has a bunch of built-in methods to quickly summarize your data and provide you with a quick general understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we don't have numerical column here, let's create one here\n",
    "df['random_column'] = np.random.random(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all numerical column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all object columns (can include multiple types).\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the return data structure of .describe() method?\n",
    "type(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to mess with it a little\n",
    "a['person'] = [len(a.doors), 19, 'less', 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all columns, including non-numeric.\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe a single column — recall that \"df.safety\" refers to a Series.\n",
    "df.safety.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the ages.\n",
    "df.random_column.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.random_column.median(), df.random_column.min(), df.random_column.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a histogram of a column (the distribution of the random value).\n",
    "df.random_column.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of occurrences of each value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.doors.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.maint.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Can also be used with numeric variables\n",
    "#   Try .sort_index() to sort by indices or .sort_values() to sort by counts.\n",
    "df.random_column.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-one\"></a>\n",
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download another dataset called Iris\n",
    "!mkdir ./data/iris\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data > ./data/iris/iris.data\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.names > ./data/iris/iris.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./data/iris/iris.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `iris.data` into a dataframe called `iris`.\n",
    "\n",
    "**DO NOT OVERWRITE `df` AS WE ARE STILL USING THAT DATAFRAME LATER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "iris = pd.read_csv('./data/iris/iris.data', names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the head and the tail of the `iris` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the default index, datatypes, and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the size of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the `petal_width` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average petal width for the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of occurrences of each species value in the `class` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filtering-and-sorting\"></a>\n",
    "### Filtering and Sorting (Using `df` Dataframe)\n",
    "- **Objective:** Filter and sort data using Pandas.\n",
    "\n",
    "We can use simple operator comparisons on columns to extract relevant or drop irrelevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logical filtering: Only show records with low safety.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series of Booleans…\n",
    "# In Pandas, this comparison is performed element-wise on each row of data.\n",
    "df[df['safety'] == 'low'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# …and use that Series to filter rows.\n",
    "# In Pandas, indexing a DataFrame by a Series of Booleans only selects rows that are True in the Boolean.\n",
    "mask  = df.safety == 'low'\n",
    "df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a dataframe with big luggage boot 'lug_boot' only\n",
    "mask = df.lug_boot == 'big'\n",
    "df[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alter dataframe entries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: This creates a view of the original DataFrame, not a new DataFrame.\n",
    "\n",
    "# If you alter this view (e.g., by storing it in a variable and altering that)\n",
    "# You will alter only the slice of the DataFrame and not the actual DataFrame itself\n",
    "# Here, notice that Pandas gives you a SettingWithCopyWarning to alert you of this.\n",
    "\n",
    "# It is best practice to use .loc and .iloc instead of the syntax below\n",
    "\n",
    "df['random_column'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one column from the filtered results.\n",
    "# df.iloc[row_index, column_index]\n",
    "df.columns.get_loc('random_column')    # this returns the column index based on column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1, 7] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts of resulting Series\n",
    "df.random_column.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.random_column.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logical filtering with multiple conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ampersand for `AND` condition. (This is a \"bitwise\" `AND`.)\n",
    "# Important: You MUST put parentheses around each expression because `&` has a higher precedence than `<`.\n",
    "# Pipe for `OR` condition. (This is a \"bitwise\" `OR`.)\n",
    "# Important: You MUST put parentheses around each expression because `|` has a higher precedence than `<`.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.buying == 'vhigh') & (df.person == '2')\n",
    "df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.maint == 'vhigh') & \\\n",
    "       (df.doors != '2') | \\\n",
    "       (df.safety == 'high')\n",
    "df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferred alternative\n",
    "df[df.safety.isin(['high'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a Series.\n",
    "df.random_column.sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('random_column', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort by multiple columns.\n",
    "df.sort_values(['random_column', 'doors'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Use the `iris.data` or `iris` dataframe from earlier to complete the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter DataFrame to only include `petal_length` greater than 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average `sepal_length` for those with `petal_length` greater than 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `sepal_width` column values in the iris dataframe to a constant number, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"columns\"></a>\n",
    "### Renaming, Adding, and Removing Columns\n",
    "\n",
    "- **Objective:** Manipulate `DataFrame` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column labels\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rename one or more columns in a single output using value mapping.\n",
    "df.rename(columns={'doors': 'num_doors',\n",
    "                   'person': 'num_person'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename one or more columns in the original DataFrame.\n",
    "df.rename(columns={'doors': 'num_doors',\n",
    "                   'person': 'num_person'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all column names using a list of matching length.\n",
    "cols = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class', 'rand_col'] \n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Easy Column Operations**<br>\n",
    "Rather than having to reference indexes and create for loops to do column-wise operations, Pandas is smart and knows that when we add columns together we want to add the values in each row together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column as a function of existing columns.\n",
    "# 1) doors_persons: doors + '_' + persons\n",
    "# 2) rand_col_1000: rand_col * 1000\n",
    "df['doors_persons'] = df.doors + '_' + df.persons\n",
    "df['rand_col_1000'] = df.rand_col * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way of adding new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.assign(persons_maint=df.persons+'&'+df.doors,\n",
    "          nothing=None).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.assign` does not store the newly created columns back into the dataframe unless the dataframe is explicitly assigned back to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(persons_maint=df.persons+'&'+df.doors,\n",
    "               nothing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to pull up the documentation of a specific method\n",
    "df.drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# axis=0 for rows, 1 for columns\n",
    "df.drop('rand_col_1000', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns.\n",
    "df.drop(['rand_col_1000', 'nothing'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop on the original DataFrame rather than returning a new one.\n",
    "df.drop(['rand_col_1000', 'nothing'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df.rand_col == 3]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Sometimes, values will be missing from the source data or as a byproduct of manipulations. It is very important to detect missing data. Missing data can:\n",
    "\n",
    "- Make the entire row ineligible to be training data for a model.\n",
    "- Hint at data-collection errors.\n",
    "- Indicate improper conversion or manipulation.\n",
    "- Actually not be missing — it sometimes means \"zero,\" \"false,\" \"not applicable,\" or \"entered an empty string.\"\n",
    "\n",
    "For example, a `.csv` file might have a missing value in some data fields:\n",
    "\n",
    "```\n",
    "tool_name,material,cost\n",
    "hammer,wood,8\n",
    "chainsaw,,\n",
    "wrench,metal,5\n",
    "```\n",
    "\n",
    "When this data is imported, \"null\" values will be stored in the second row (in the \"material\" and \"cost\" columns).\n",
    "\n",
    "> In Pandas, a \"null\" value is either `None` or `np.NaN` (Not a Number). Many fixed-size numeric datatypes (such as integers) do not have a way of representing `np.NaN`. So, numeric columns will be promoted to floating-point datatypes that do support it. For example, when importing the `.csv` file above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:3, df.columns.get_loc('class')] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values are usually excluded in calculations by default.\n",
    "df['class'].value_counts()              # Excludes missing values in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values in a Series.\n",
    "# True if missing, False if not missing\n",
    "df['class'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True if not missing, False if missing\n",
    "df['class'].notnull().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only show rows where class is not missing.\n",
    "df[df['class'].notnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Pandas Axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sums \"down\" the 0 axis (rows) — so, we get the sums of each column\n",
    "df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis=0 is the default.\n",
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another random column here\n",
    "df['rand_col_2'] = np.random.random(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sums \"across\" the 1 axis (columns) — so, we get the sums of numeric values in the row \n",
    "df['random_col_sum'] = df[['rand_col', 'rand_col_2']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find missing values in a `DataFrame`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of Booleans\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the missing values in each column — remember by default, axis=0.\n",
    "print((df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row if ANY values are missing from any column — can be dangerous!\n",
    "df.dropna().head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop a row only if ALL values are missing.\n",
    "df.dropna(how='all').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with \"NA\" — this is dangerous to do without manually verifying them!\n",
    "df['class'].fillna(value='acc').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifies \"drinks\" in-place\n",
    "df['class'].fillna(value='acc', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-three\"></a>\n",
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's download another dataset\n",
    "!mkdir ./data/hepatitis\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/hepatitis/hepatitis.data > ./data/hepatitis/hepatitis.data\n",
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/hepatitis/hepatitis.names > ./data/hepatitis/hepatitis.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat ./data/hepatitis/hepatitis.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read hepatitis.data into a DataFrame called \"hp\".\n",
    "cols = ['class', 'age', 'sex', 'steroid', 'antivirals', 'fatigue', 'malaise', 'anorexia', 'liver_big',\n",
    "        'liver_firm', 'spleen_palpable', 'spiders', 'ascites', 'varices', 'bilirubin',\n",
    "        'alk_phosphate', 'sgot', 'albumin', 'protime', 'histology']\n",
    "hp = pd.read_csv('./data/hepatitis/hepatitis.data', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the dataframe looks like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you notice any issues with the data here** \n",
    "\n",
    " (Hint: Read the explanation about the data more carefully, something to do with the missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-read the data into a data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data types of the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the type of age and sex columns from int to Categories**\n",
    "\n",
    "Hint: Google astype pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those with age greater or equal to 30, what's the most common class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a DataFrame containing only sex is 1 and steriods greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows remain if you drop all rows with any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split-apply-combine\"></a>\n",
    "### Split-Apply-Combine\n",
    "\n",
    "Split-apply-combine is a pattern for analyzing data. Suppose we want to find mean beer consumption per country. Then:\n",
    "\n",
    "- **Split:** We group data by continent.\n",
    "- **Apply:** For each group, we apply the `mean()` function to find the average beer consumption.\n",
    "- **Combine:** We now combine the continent names with the `mean()`s to produce a summary of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For each sex, calculate the mean alk_phosphate.\n",
    "hp.groupby('sex').alk_phosphate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sex, calculate the mean of all numeric columns.\n",
    "hp.groupby('sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sex, describe age.\n",
    "hp.groupby('sex').age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar, but outputs a DataFrame and can be customized — \"agg\" allows you to aggregate results of Series functions\n",
    "hp.groupby('sex').age.agg(['count', 'mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.groupby('sex').age.agg(['count', 'mean', 'min', 'max']).sort_values('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "In this session, we went through an introductory tutorial on how to use Pandas to perform exploratory data analysis. Note that the material covered today was designed for today's workshop purpose only. Here are some additional topics to look into using Pandas,\n",
    "<ul>\n",
    "    <li>Check duplicate</li>\n",
    "    <li>iloc vs loc</li>\n",
    "    <li>Joins and merges</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
